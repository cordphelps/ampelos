---
title: "ampelos V2"
output: 
 github_document: default
 
always_allow_html: true
---

![landscape](./photos/landscapeOak.JPG)

## Can the influence of a 'semi-natural habitat' (SNH) organic vineyard field margin be quantified in the context of the population of beneficial spiders found in the canopy?


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, results='hide')

# https://yihui.org/knitr/options/

# echo: (TRUE; logical or numeric) Whether to display the source code
# results: ('markup'; character) Controls how to display the text results.
# warning: (TRUE; logical) Whether to preserve warnings
# error: (TRUE; logical) Whether to preserve errors
# include: (TRUE; logical) Whether to include the chunk output in the output document.
# 
```

```{r localCode, echo=FALSE, include=FALSE}

################## pdf flag for save_kable() tables ##############

pdf <- FALSE

##################################################################

source('/Users/rcphelps/code/thesis/ampelos/code/bayesNoClusters.R')

output.path <- "/Users/rcphelps/code/thesis/ampelos/code/output/"

setwd("/Users/rcphelps/code/thesis/ampelos")

library(tidyverse)
library(dplyr)
library(knitr)
library(kableExtra)


```



```{r makeTibbles, echo=FALSE, include=TRUE, results='asis', message=F, warning=T}


# "weeks 23-25",  "weeks 26-31", "weeks 32-34"

source.url <- c("https://raw.githubusercontent.com/cordphelps/ampelos/master/data/bugs.csv")


bugs.tibl <- dplyr::as_tibble(read.csv(source.url, header=TRUE, row.names=NULL))

binomial.spiders.pm.control.p1.tbl <- bugs.tibl %>% 
  dplyr::filter(time == 'pm', transect=='control', week < 26) %>%
  dplyr::select(Thomisidae..crab.spider.) %>% 
  dplyr::mutate(Thomisidae..crab.spider. = replace(Thomisidae..crab.spider., Thomisidae..crab.spider. > 0, 1))

binomial.spiders.pm.control.p1.theta <- mean(binomial.spiders.pm.control.p1.tbl$Thomisidae..crab.spider.)

binomial.spiders.pm.SNH.p1.tbl <- bugs.tibl %>% 
  dplyr::filter(time == 'pm', transect=='oakMargin', week < 26) %>%
  dplyr::select(Thomisidae..crab.spider.) %>% 
  dplyr::mutate(Thomisidae..crab.spider. = replace(Thomisidae..crab.spider., Thomisidae..crab.spider. > 0, 1))

binomial.spiders.pm.SNH.p1.theta <- mean(binomial.spiders.pm.SNH.p1.tbl$Thomisidae..crab.spider.)

thomisidae.day.control.tbl <- bugs.tibl %>% 
  dplyr::filter(time == 'pm', transect=='control')  %>%
  dplyr::group_by(julian, transect) %>%
  dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.),
            time = 'pm',
            week=week, transect=transect,
            .groups = 'drop') %>%
  dplyr::distinct()

thomisidae.night.control.tbl <- bugs.tibl %>% 
  dplyr::filter(time == 'am', transect=='control')  %>%
  dplyr::group_by(julian, transect) %>%
  dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.),
            time = 'am',
            week=week, transect=transect,
            .groups = 'drop') %>%
  dplyr::distinct()

thomisidae.day.SNH.tbl <- bugs.tibl %>% 
  dplyr::filter(time == 'pm', transect=='oakMargin')  %>%
  dplyr::group_by(julian, transect) %>%
  dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.),
            time = 'pm',
            week=week, transect=transect,
            .groups = 'drop') %>%
  dplyr::distinct()

thomisidae.night.SNH.tbl <- bugs.tibl %>% 
  dplyr::filter(time == 'am', transect=='oakMargin')  %>%
  dplyr::group_by(julian, transect) %>%
  dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.),
            time = 'am',
            week=week, transect=transect,
            .groups = 'drop') %>%
  dplyr::distinct()

# **************************************************** #

thomisidae.period1.SNH.tibl <- bugs.tibl %>% 
  dplyr::filter(time == 'pm', transect=='oakMargin')  %>%
  dplyr::filter(week < 26) %>%
  dplyr::group_by(julian, transect) %>%
  dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.),
            time = time,
            week=week, transect=transect,
            .groups = 'drop') %>%
  dplyr::distinct()

thomisidae.period1.control.tibl <- bugs.tibl %>% 
  dplyr::filter(time == 'pm', transect == 'control') %>%
  dplyr::filter(week < 26) %>%
  dplyr::group_by(julian, transect) %>%
  dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.),
            time = time,
            week=week, transect=transect,
            .groups = 'drop') %>%
  dplyr::distinct()

thomisidae.period2.SNH.tibl <- bugs.tibl %>% 
  dplyr::filter(time == 'pm', transect=='oakMargin')  %>%
  dplyr::filter(week > 25 & week < 32) %>%
    dplyr::group_by(julian, transect) %>%
  dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.),
            time = time,
            week=week, transect=transect,
            .groups = 'drop') %>%
  dplyr::distinct()

thomisidae.period2.control.tibl <- bugs.tibl %>% 
  dplyr::filter(time == 'pm', transect == 'control') %>%
  dplyr::filter(week > 25 & week < 32) %>%
  dplyr::group_by(julian, transect) %>%
  dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.),
            time = time,
            week=week, transect=transect,
            .groups = 'drop') %>%
  dplyr::distinct()

thomisidae.period3.SNH.tibl <- bugs.tibl %>% 
  dplyr::filter(time == 'pm', transect=='oakMargin')  %>%
  dplyr::filter(week > 31) %>%
  dplyr::group_by(julian, transect) %>%
  dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.),
            time = time,
            week=week, transect=transect,
            .groups = 'drop') %>%
  dplyr::distinct()

thomisidae.period3.control.tibl <- bugs.tibl %>% 
  dplyr::filter(time == 'pm', transect == 'control') %>%
  dplyr::filter(week > 31) %>%
  dplyr::group_by(julian, transect) %>%
  dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.),
            time = time,
            week=week, transect=transect,
            .groups = 'drop') %>%
  dplyr::distinct()

combo.period1.tibl <- bugs.tibl %>% 
  dplyr::filter(time != 'am') %>%
  dplyr::filter(week < 26)

combo.period2.tibl <- bugs.tibl %>% 
  dplyr::filter(time != 'am') %>%
  dplyr::filter(week > 25 & week < 32)

combo.period3.tibl <- bugs.tibl %>% 
  dplyr::filter(time != 'am') %>%
  dplyr::filter(week > 31)


```



```{r bugs, echo=FALSE, include=TRUE, results=FALSE, message=F, warning=F, out.width=c('50%', '50%'), fig.show='hold'}

bug.lst <- list()

bug.lst <- scanBugPercentages(bugs.tibl)

bug.lst <- createFamilyPercentages(bug.lst)

gg <- plotBugPercentages(bug.lst, spidersOnly=FALSE)

print(gg)

    fileName <- "ggsave.insectPop.1.1.pdf"
    fullPath <- paste(output.path, "/", fileName, sep="")
    if (file.exists(fullPath)) { file.remove(fullPath) }

ggsave(fileName, plot = gg, device = NULL, path = output.path,
       scale = 1, width = 6, height = NA, dpi = 300, limitsize = TRUE,
       units = c("in", "cm", "mm"))

gg <- plotBugPercentages(bug.lst, spidersOnly=TRUE)

print(gg)

    fileName <- "ggsave.insectPop.1.2.pdf"
    fullPath <- paste(output.path, "/", fileName, sep="")
    if (file.exists(fullPath)) { file.remove(fullPath) }

ggsave(fileName, plot = gg, device = NULL, path = output.path,
       scale = 1, width = 6, height = NA, dpi = 300, limitsize = TRUE,
       units = c("in", "cm", "mm"))

```

## a control and SNH transect each consisted of 3 rows of 10 vane traps. ( https://www.bluevanetraps.com/ )

![transect layout](./images/transectLayout.jpg)

## typical trap positioning; bowl in the fruit zone, vanes intersecting the canopy

![landscape](./photos/typicalTrap.JPG)

## example trap sequence

![landscape](./photos/trapSequence.JPG)


```{r cohensCalc, echo=FALSE, include=FALSE, results='asis', message=F, warning=T}

# include=FALSE : unable to suppress JGmisc::cohens.d output


# summary of estimators, standardizers, and recommended use
# table 1, "pooled SD" 
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3840331/
# cite:
# Lakens D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs. Frontiers in psychology, 4, 863. https://doi.org/10.3389/fpsyg.2013.00863

library(JGmisc)

# https://rdrr.io/github/jasongraf1/JGmisc/man/cohens.d.html
# JGmisc::cohens.d gnerates
#   m1 = mean of first variable
#   m2 = mean of second variable
#   ss.variance = pooled variance
#   d = cohen's d score

# invisible(capture.output()) silences the verbose output of JGmisc::cohens.d()
# https://stackoverflow.com/questions/2723034/suppress-output-of-a-function/61571259#61571259

invisible({capture.output({

period1.stats <- JGmisc::cohens.d(thomisidae.period1.SNH.tibl$totalSpiders, thomisidae.period1.control.tibl$totalSpiders)

period2.stats <- JGmisc::cohens.d(thomisidae.period2.SNH.tibl$totalSpiders, thomisidae.period2.control.tibl$totalSpiders)

period3.stats <- JGmisc::cohens.d(thomisidae.period3.SNH.tibl$totalSpiders, thomisidae.period3.control.tibl$totalSpiders)

})})

################# for the hypothetical population
################# values used in the bayes analysis

trapEfficiency <- .1   

# for the purposes of evaluating the model (and calculating an effect likelihood)
# we suggest a hypothetical population (for each transect) which is the 
# SNH trapped mean divided by 'trap efficiency'
# (note that 'trap efficiency' does not have to be accurately known, we are just
# using it to generate a hypothetical population)

period1.hypoPopulation <- period1.stats$m1 / trapEfficiency 
period2.hypoPopulation <- period2.stats$m1 / trapEfficiency 
period3.hypoPopulation <- period3.stats$m1 / trapEfficiency 

#################
#################

```


```{r cohensStats, echo=FALSE, include=FALSE, results=F, message=F, warning=T}


stats.tbl <- tribble(~period, ~cohens.d, ~SNHmean, ~controlMean,
                     "weeks 23-25", 
                     round(period1.stats$d,2), 
                     round(period1.stats$m1,2), 
                     round(period1.stats$m2,2),
                     "weeks 26-31", 
                     round(period2.stats$d,2), 
                     round(period2.stats$m1,2), 
                     round(period2.stats$m2,2),
                     "weeks 32-34", 
                     round(period3.stats$d,2), 
                     round(period3.stats$m1,2), 
                     round(period3.stats$m2,2)
                      )

# New Effect Size Rules of Thumb
# Sawilowsky 2009
# https://digitalcommons.wayne.edu/cgi/viewcontent.cgi?referer=https://scholar.google.com/&httpsredir=1&article=1536&context=jmasm

# effect size, early season: d = 0.757   ('large' Cohen 1988)
# effect size, mid season:   d = 0.0348  ('very small' Sawilowsky, 2009)
# effect size, late season:  d = 0.299   ('small-medium' Cohen 1988)
#
# https://people.bath.ac.uk/pssiw/stats2/page2/page14/page14.html
# A large Cohen’s d doesn’t necessarily mean that an effect actually exists, 
# because Cohen’s d is just your best estimate of how big the effect is, 
# assuming it does exist.
#
# Nichols 2001 figure 4
# approx effect size, early season: (negative)
# approx effect size, mid season:   approx .5 'medium'
# approx effect size, late season:  approx .2 'small'
#

```


```{r cohensFile, echo=FALSE, include=FALSE, message=F, warning=T}

# tab.cap = NULL, results='asis', 


# https://community.rstudio.com/t/sizing-tables-in-pdf-documents-using-knitr-and-kableextra/19285

if (pdf==TRUE) {
  
  knitr::kable(stats.tbl, 
          caption="Comparison of SNH and control weekly daytime trapped\ncrab spider counts (Wilcoxon signed-rank test)",
          col.names = linebreak(c("seasonal period", 
                        "Cohen's d\neffect size", 
                        "SNH transect\nmean spiders per week\n(across 30 traps)", 
                        "control transect\nmean spiders per week\n(across 30 traps)")),
          escape=FALSE,
          align = "lccc",
          row.names=FALSE,
          format="latex",
          booktabs=TRUE ) %>%
    
          kableExtra::column_spec(1,width = "20%") %>%
          kableExtra::column_spec(2,width = "20%") %>%
          kableExtra::column_spec(3,width = "20%") %>%
          kableExtra::column_spec(4,width = "20%") %>%
    
          kableExtra::save_kable(paste(output.path, "table.cntlNight", ".pdf", sep=""))
  
}
  
```
  
  
```{r cohensGit, echo=FALSE, include=FALSE, results=F, message=F, warning=T}

# https://bookdown.org/yihui/rmarkdown-cookbook/kable.html#specify-column-alignment
  
  knitr::kable(stats.tbl, 
            caption="Comparison of SNH and control weekly daytime trapped\ncrab spider counts (Wilcoxon signed-rank test)",
            col.names = c("seasonal period", 
                          "Cohen's d<br/>effect size", 
                          "SNH transect<br/>mean spiders per week<br/>(across 30 traps)", 
                          "control transect<br/>mean spiders per week<br/>(across 30 traps)"
                          ),
            escape=FALSE,
            full_width=TRUE,
            font_size=10,
            align = "lccc") %>%
    
          kableExtra::column_spec(1,width = "20%") %>%
          kableExtra::column_spec(2,width = "20%") %>%
          kableExtra::column_spec(3,width = "20%") %>%
          kableExtra::column_spec(4,width = "20%")


  
```


```{r powerStats, echo=FALSE, include=FALSE, results=F, message=F, warning=T}

observations.daytime.period1 <- combo.period1.tibl %>% dplyr::group_by(julian) %>% count()
observations.daytime.period2 <- combo.period2.tibl %>% dplyr::group_by(julian) %>% count()
observations.daytime.period3 <- combo.period3.tibl %>% dplyr::group_by(julian) %>% count()

obs.period1 <- sum(observations.daytime.period1$n)
obs.period2 <- sum(observations.daytime.period2$n)
obs.period3 <- sum(observations.daytime.period3$n)


power.period1 <- pwr::pwr.t2n.test(n1 = obs.period1 / 2, 
                                   n2= obs.period1 / 2, 
                                   d = period1.stats$d, sig.level = 0.05, power = NULL)

power.period2 <- pwr::pwr.t2n.test(n1 = obs.period2 / 2, 
                                   n2= obs.period2 / 2, 
                                   d = period2.stats$d, sig.level = 0.05, power = NULL)

power.period3 <- pwr::pwr.t2n.test(n1 = obs.period3 / 2, 
                                   n2= obs.period3 / 2, 
                                   d = period3.stats$d, sig.level = 0.05, power = NULL)


stats.tbl <- tribble(~period, ~cohens.d, ~sig.level, ~power,  ~actualSampleSize,
                     "weeks 23-25", 
                     round(period1.stats$d,2), 
                     0.05, 
                     power.period1$n1,
                     round(power.period1$power, 2),
                     
                     "weeks 26-31", 
                     round(period2.stats$d,2), 
                     0.05, 
                     power.period2$n1,
                     round(power.period2$power, 2),
                     
                     "weeks 32-34", 
                     round(period3.stats$d,2), 
                     0.05, 
                     power.period3$n1,
                     round(power.period3$power, 2)
                      )

# https://community.rstudio.com/t/sizing-tables-in-pdf-documents-using-knitr-and-kableextra/19285
    
if (pdf==TRUE) {
  
    knitr::kable(stats.tbl, 
               
          caption="power analysis by seasonal period: two sample t test",
          col.names = linebreak(c("seasonal period", 
                        "Cohen's d effect size\n(calculated)", 
                        "alpha\n(proposed)", 
                        "sample size\n(actual)",
                        "power\n(calculated)" 
                        )),
          escape=FALSE,
          align = "lcccc",
          row.names=FALSE,
          format="latex", 
          booktabs=TRUE ) %>%
    
          kableExtra::column_spec(1,width = "20%") %>%
          kableExtra::column_spec(2,width = "20%") %>%
          kableExtra::column_spec(3,width = "20%") %>%
          kableExtra::column_spec(4,width = "20%") %>%
          kableExtra::column_spec(5,width = "20%") %>%
    
          kableExtra::save_kable(paste(output.path, "table.power", ".pdf", sep=""))
  
}
  
knitr::kable(stats.tbl, caption="power analysis by seasonal period: two sample t test",
             col.names = c("seasonal period", 
                           "Cohen's d<br/>effect size<br/>(calculated)", 
                           "alpha<br/>(proposed)", 
                           "sample size<br/>(actual)",
                           "power<br/>(calculated)" 
                           ),
             escape=FALSE,
             full_width=TRUE,
             font_size=10,
             align = "lcccc") %>%
  
            kableExtra::column_spec(1,width = "20%") %>%
            kableExtra::column_spec(2,width = "20%") %>%
            kableExtra::column_spec(3,width = "20%") %>%
            kableExtra::column_spec(4,width = "20%") %>%
            kableExtra::column_spec(5,width = "20%")

```




```{r rawDistributions, echo=FALSE, include=TRUE, results="hide", message=F, warning=T, out.width=c('50%', '50%'), fig.show='hold' }

plotRawWeeklyV2(day=thomisidae.day.SNH.tbl, night=thomisidae.night.SNH.tbl, where="SNH")

plotRawWeeklyV2(day=thomisidae.day.control.tbl, night=thomisidae.night.control.tbl, where="control")


```



```{r wilcox-day-night, echo=FALSE, include=F, results=F, message=F, warning=T}

# compare day/night distributions for each transect

snh.stats <- wilcoxStats(vector1 = thomisidae.day.SNH.tbl, 
                         vector2 = thomisidae.night.SNH.tbl,
                         byTransect=FALSE)

control.stats <- wilcoxStats(vector1 = thomisidae.day.control.tbl,
                             vector2 = thomisidae.night.control.tbl,
                             byTransect=FALSE)

stats.tbl <- tribble(~transect, ~wilcox.p, ~effectSize, ~comment,
                     "SNH", round(snh.stats[[1]],3), 
                     round(snh.stats[[2]],3), 
                     snh.stats[[3]],
                     "control", round(control.stats[[1]],3), 
                     round(control.stats[[2]],3), 
                     control.stats[[3]]
                      )

if (pdf==TRUE) {
  
  # https://community.rstudio.com/t/sizing-tables-in-pdf-documents-using-knitr-and-kableextra/19285
  knitr::kable(stats.tbl, 
               
          caption="Comparison of daylight and night-time weekly trapped\nspider counts by transect (Wilcoxon signed-rank test)",
          col.names = c("seasonal period", 
                        "p value", 
                        "effect metric", 
                        "effect magnitude"),
          align = "lccc",
          row.names=FALSE,
          format="latex", 
          booktabs=TRUE ) %>%
    
          kableExtra::column_spec(1,width = "20%") %>%
          kableExtra::column_spec(2,width = "20%") %>%
          kableExtra::column_spec(3,width = "20%") %>%
          kableExtra::column_spec(4,width = "20%") %>%
    
          kableExtra::save_kable(paste(output.path, "table.dayNight", ".pdf", sep=""))
  
  }
  

# https://bookdown.org/yihui/rmarkdown-cookbook/kable.html#specify-column-alignment
knitr::kable(stats.tbl, caption="Comparison of daylight and night-time weekly trapped\nspider counts by transect (Wilcoxon signed-rank test)",
             col.names = c("transect", 
                           "p value", 
                           "effect metric", 
                           "effect magnitude"),
            full_width=TRUE,
            font_size=10,
            align = "lccc") %>%
  
            kableExtra::column_spec(1,width = "20%") %>%
            kableExtra::column_spec(2,width = "20%") %>%
            kableExtra::column_spec(3,width = "20%") %>%
            kableExtra::column_spec(4,width = "20%") 

# rcp: "We conclude that the daylight and nighttime rates of trapped spiders are
# significantly different for both SNH and control transects. (p value = 0.01, 
# effect metric r = 0.4)"

```


```{r wilcox-SNH-control, echo=FALSE, include=F, results='asis', message=F, warning=T}

# compare day/night distributions for each transect

period1.stats <- wilcoxStats(vector1 = thomisidae.period1.SNH.tibl, 
                         vector2 = thomisidae.period1.control.tibl, 
                         byTransect=TRUE)

period2.stats <- wilcoxStats(vector1 = thomisidae.period2.SNH.tibl, 
                         vector2 = thomisidae.period2.control.tibl, 
                         byTransect=TRUE)

period3.stats <- wilcoxStats(vector1 = thomisidae.period3.SNH.tibl, 
                         vector2 = thomisidae.period3.control.tibl, 
                         byTransect=TRUE)

stats.tbl <- tribble(~seasonalPeriod, ~wilcox.p, ~effectSize, ~comment,
                     "weeks 23-25", round(period1.stats[[1]],3), 
                     round(period1.stats[[2]],3), 
                     period1.stats[[3]],
                     "weeks 26-31", round(period2.stats[[1]],3), 
                     round(period2.stats[[2]],3), 
                     period2.stats[[3]],
                     "weeks 31-34", round(period3.stats[[1]],3), 
                     round(period3.stats[[2]],3), 
                     period3.stats[[3]]
                      )

if (pdf==TRUE) {
  # output for pdf
  # https://community.rstudio.com/t/sizing-tables-in-pdf-documents-using-knitr-and-kableextra/19285
  knitr::kable(stats.tbl, 
               
          caption="Comparison of SNH and control weekly daytime trapped\nspider counts by seasonal period (Wilcoxon signed-rank test)",
          col.names = c("seasonal period", 
                        "p value", 
                        "effect metric", 
                        "effect magnitude"),
          
          align = "lccc",
          row.names=FALSE,
          format="latex", 
          booktabs=TRUE ) %>%
    
          kableExtra::column_spec(1,width = "20%") %>%
          kableExtra::column_spec(2,width = "20%") %>%
          kableExtra::column_spec(3,width = "20%") %>%
          kableExtra::column_spec(4,width = "20%") %>%
    
          kableExtra::save_kable(paste(output.path, "table.SNHcontrol", ".pdf", sep=""))
  
}

# https://bookdown.org/yihui/rmarkdown-cookbook/kable.html#specify-column-alignment
knitr::kable(stats.tbl, caption="Comparison of SNH and control weekly daytime trapped\nspider counts by seasonal period (Wilcoxon signed-rank test)",
             col.names = c("seasonal period", 
                           "p value", 
                           "effect metric", 
                           "effect magnitude"),
            full_width=TRUE,
            font_size=10,
            align = "lccc") %>%
  
            kableExtra::column_spec(1,width = "20%") %>%
            kableExtra::column_spec(2,width = "20%") %>%
            kableExtra::column_spec(3,width = "20%") %>%
            kableExtra::column_spec(4,width = "20%") 




```


```{r densityPlots, echo=FALSE, include=TRUE, results="hide", message=F, warning=T, out.width=c('50%', '50%'), fig.show='hold' }


input.tibl <- combo.period1.tibl %>% mutate(transect=replace(as.character(transect), transect=='oakMargin', 'SNH')) %>% as_tibble()

densityNoFacets(tibble=input.tibl, periodString="weeks 23-25")
densityFacets(tibble=input.tibl, periodString="weeks 23-25")

input.tibl <- combo.period2.tibl %>% mutate(transect=replace(as.character(transect), transect=='oakMargin', 'SNH')) %>% as_tibble()

densityNoFacets(tibble=input.tibl, periodString="weeks 26-31")
densityFacets(tibble=input.tibl, periodString="weeks 26-31")

input.tibl <- combo.period3.tibl %>% mutate(transect=replace(as.character(transect), transect=='oakMargin', 'SNH')) %>% as_tibble()

print( densityNoFacets(tibble=input.tibl, periodString="weeks 32-34") )
print( densityFacets(tibble=input.tibl, periodString="weeks 32-34") )


```



```{r errorBars, echo=FALSE, include=TRUE, results="asis", message=F, warning=F, out.width=c('33%', '33%', '33%'), fig.show='hold'}

# calculate the mean and SE of traps (like Altieri)
# https://stackoverflow.com/questions/2676554/in-r-how-to-find-the-standard-error-of-the-mean
combo1.means.tibl <- combo.period1.tibl %>%
    dplyr::group_by(transect, positionX) %>%
    dplyr::summarize(mean = mean(Thomisidae..crab.spider., na.rm=TRUE),
              se = sd(Thomisidae..crab.spider., na.rm=TRUE) /
                    sqrt(length(position)),
              observations = n() ) %>% 
    dplyr::mutate(transect=replace(as.character(transect), transect=='oakMargin', 'SNH'))

combo2.means.tibl <- combo.period2.tibl %>%
    dplyr::group_by(transect, positionX) %>%
    dplyr::summarize(mean = mean(Thomisidae..crab.spider., na.rm=TRUE),
              se = sd(Thomisidae..crab.spider., na.rm=TRUE) /
                    sqrt(length(position)),
              observations = n() ) %>% 
    dplyr::mutate(transect=replace(as.character(transect), transect=='oakMargin', 'SNH'))


combo3.means.tibl <- combo.period3.tibl %>%
    dplyr::group_by(transect, positionX) %>%
    dplyr::summarize(mean = mean(Thomisidae..crab.spider., na.rm=TRUE),
              se = sd(Thomisidae..crab.spider., na.rm=TRUE) /
                    sqrt(length(position)),
              observations = n() ) %>% 
    dplyr::mutate(transect=replace(as.character(transect), transect=='oakMargin', 'SNH'))
      

# Two data samples are independent if they come from distinct populations and the samples do not affect each other. Using the Mann-Whitney-Wilcoxon Test, we can decide whether the population distributions are identical without assuming them to follow the normal distribution.
# http://www.r-tutor.com/elementary-statistics/non-parametric-methods/mann-whitney-wilcoxon-test

# wilcox.test(mean ~ transect, data=combo1.means.tibl, correct=FALSE)
# wilcox.test(mean ~ transect, data=combo2.means.tibl, correct=FALSE)
# wilcox.test(mean ~ transect, data=combo3.means.tibl, correct=FALSE)

# ***    'mean' shoud be OK    ***
# 2. If the data represent essentially discrete values (e.g. they
# are count data, or ordered categorical), where ties are intrinsically
# possible, then strictly speaking the Mann-Whitney test is not
# appropriate, since its distribution function depends on the assumption
# of continuity which is not true here.
# https://stat.ethz.ch/pipermail/r-help/2009-December/415767.html

# for more than 2 groups
# http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r


errorBars(tibble=combo1.means.tibl, periodString = "weeks 23-25", observations = 27)

errorBars(tibble=combo2.means.tibl, periodString = "weeks 26-31", observations = 39)

errorBars(tibble=combo3.means.tibl, periodString = "weeks 32-34", observations = 27)



```


```{r bayes, echo=FALSE, include=TRUE, results="hide", message=F, warning=T, out.width=c('50%', '50%'), fig.show='hold'}


seed <- 101

# for each seasonal period
hypotheticalPopulation <- c(period1.hypoPopulation, 
                            period2.hypoPopulation, 
                            period3.hypoPopulation)
# hypotheticalPopulation <- c(58.13,15.93,6.67)



    # organize data into
    #       "week", "transect", "time", "cluster", "totalSpiders"
    # ( already done by evaluateDailySpiderCounts() )
    #

    #         existing models will be read from disc
    #         with TRUE/FALSE logic in generateLikelihoodV2() ......
    
    
    filtered.df <- bugs.tibl %>% 
      dplyr::filter(time != 'am') %>% 
      dplyr::group_by(week, transect) %>%
      dplyr::summarize(totalSpiders = sum(Thomisidae..crab.spider.))
      
      # rename(totalSpiders = Thomisidae..crab.spider.)
    
    
    # read data from disc with fromDisc=TRUE
    # re-build brm model and posterior distribution with fromDisc=FALSE
    
    # compare predictions for a high contact and low contact vines
    
    gg.likelihood.pm.lst <- list()
    
    gg.likelihood.pm.lst <- generateLikelihoodV3(df=filtered.df,
              daytime='pm', fromDisc=TRUE, path= output.path,
              randomSeed=seed, hp=hypotheticalPopulation)
    

```

```{r test, echo=FALSE, include=F, results=F, message=F, warning=T, tab.cap = NULL}

if (TRUE) {
  
  source('/Users/rcphelps/code/thesis/ampelos/code/bayesNoClusters.R')
  
  test.lst <- examineModelOutput(df=filtered.df,
              path= output.path,
              daytime = 'pm',
              hp=hypotheticalPopulation)
  
    # test.lst[[1]]                     # plotliklihoodV2 output
    # test.lst[[2]] <- post.df.list     # 
    # test.lst[[3]] <- modelOutput
    # test.lst[[4]] <- post.df.list   	# contains lambda high, low, and diff
    # test.lst[[5]] <- likelihood.df
  
  test.df <- test.lst[[4]] %>% as.data.frame()
  
  like.df <- test.lst[[5]]
  
  #max(test.df$lambda_high)
  #max(test.df$lambda_low)
  
  #period2.hypoPopulation
  #period3.hypoPopulation
  #hypotheticalPopulation
  
  
  stats.tbl <- tribble(~seasonalPeriod, 
                       ~likelihood,
                       ~hypoPop, 
                       ~modelHighContactMean,
                       ~modelLowContactMean,
                       
                     "weeks 23-25", 
                     round(like.df$plausibility[[1]] * 100 , 1),
                     round(period1.hypoPopulation, 0), 
                     round((mean(test.df$lambda_high) / period1.hypoPopulation) * 100, 1),
                     round((mean(test.df$lambda_low) / period1.hypoPopulation) * 100, 1),
                     
                     "weeks 26-31", 
                     round(like.df$plausibility[[2]] * 100 , 1),
                     round(period2.hypoPopulation, 0), 
                     round((mean(test.df$lambda_high.1) / period2.hypoPopulation) * 100, 1),
                     round((mean(test.df$lambda_low.1) / period2.hypoPopulation) * 100, 1),
                     
                     "weeks 31-34", 
                     round(like.df$plausibility[[3]] * 100 , 1),
                     round(period3.hypoPopulation, 0), 
                     round((mean(test.df$lambda_high.2) / period3.hypoPopulation) * 100, 1),
                     round((mean(test.df$lambda_low.2) / period3.hypoPopulation) * 100, 1)
                      )

  # https://bookdown.org/yihui/rmarkdown-cookbook/kable.html#specify-column-alignment
  
if (pdf==TRUE) {
  # output for pdf
  # https://community.rstudio.com/t/sizing-tables-in-pdf-documents-using-knitr-and-kableextra/19285
  knitr::kable(stats.tbl, 
               
          caption="interaction model statistics for a hypothetical population by time period",
          col.names = linebreak(c("seasonal period", 
                        "positive SNH effect\nplausibility\n(percent)",
                        "population exposed to the traps\n(example)",
                        "SNH mean\ntrapped spiders\n(percent)", 
                        "control mean\ntrapped spiders\n(percent)" )),
          escape=FALSE,
          align = "lcccc",
          row.names=FALSE,
          format="latex", 
          booktabs=TRUE ) %>%

          # remove_table_numbers %>%
    
          kableExtra::column_spec(1,width = "20%") %>%
          kableExtra::column_spec(2,width = "20%") %>%
          kableExtra::column_spec(3,width = "20%") %>%
          kableExtra::column_spec(4,width = "20%") %>%
          kableExtra::column_spec(5,width = "20%") %>%
    
          # add_indent(c(2:3)) %>%
          # add_header_above(header="Header") %>%
          #footnote(c("Source; 2000 Census",
          #   "Source: 2010 Census",
          #   "Really long footnote that increases the width of the table.")) %>%
    
          kableExtra::save_kable(paste(output.path, "table.1", ".pdf", sep=""))
  
  
}


    # output for markdown
    knitr::kable(stats.tbl, 
               
          caption="<b>interaction model statistics for a hypothetical population by time period</b>",
          col.names = c("seasonal period",
                        "positive SNH effect<br/>plausibility<br/>(percent)",
                        "population<br/>exposed to the traps<br/>(example)",
                        "SNH transect<br/>modelled mean<br/>trapped spiders<br/>(percent)", 
                        "control transect<br/>modelled mean<br/>trapped spiders<br/>(percent)" ),

          escape=FALSE,
          full_width=TRUE,
          font_size=10,          
          align = "lcccc") %>%
      
          kableExtra::column_spec(1,width = "20%") %>%
          kableExtra::column_spec(2,width = "20%") %>%
          kableExtra::column_spec(3,width = "20%") %>%
          kableExtra::column_spec(4,width = "20%") %>%
          kableExtra::column_spec(5,width = "20%")
  
}

```



```{r modelDiags, echo=FALSE, include=FALSE, results=FALSE, message=T, warning=T}


if (TRUE) {
  
    time <- "pm"
    
	  fullPath.rds <- paste(output.path, "listV2-", time, ".rds", sep="")

    # read the 3 models from disc and run diags
	  gg.lst <- list()
    gg.lst <- modelDiagsV3(daytime = time, hp=hypotheticalPopulation, rds=fullPath.rds)

  }


```



```{r bayesPrimaryPlots, echo=FALSE, include=TRUE, results="hide", message=F, warning=T, out.width=c('50%', '50%'), fig.show='hold'}

    # just print the plausibility graph and distributions
    
    print(gg.likelihood.pm.lst[[1]])
      
    fileName <- paste("ggsave.plausibility.1.v2.pdf", sep="")
    fullPath <- paste(output.path, "/", fileName, sep="")
    if (file.exists(fullPath)) { file.remove(fullPath) }
      
    ggsave(fileName, 
              plot = gg.likelihood.pm.lst[[1]], 
              device = NULL, path = output.path,
              scale = 1, width = 6, height = NA, dpi = 300, limitsize = TRUE,
              units = c("in", "cm", "mm"))

  
    print(gg.lst[[1]])
  
    fileName <- paste("ggsave.poisson.4.2.V2.pdf", sep="")
    fullPath <- paste(output.path, "/", fileName, sep="")
    if (file.exists(fullPath)) { file.remove(fullPath) }

    ggsave(fileName, plot = gg.lst[[1]], 
              device = NULL, path = output.path,
              scale = 1, width = 6, height = NA, dpi = 300, limitsize = TRUE,
              units = c("in", "cm", "mm"))
    
    

```



```{r posteriorGraphs, echo=FALSE, include=TRUE, results="hide", message=F, warning=T, out.width=c('33%', '33%', '33%'), fig.show='hold'}

# display the posterior graphs 

    for (i in 2:length(gg.likelihood.pm.lst)) {
    
      print(gg.likelihood.pm.lst[[i]])
      
      fileName <- paste("ggsave.plausibility.", i, ".v2.pdf", sep="")
      fullPath <- paste(output.path, "/", fileName, sep="")
      if (file.exists(fullPath)) { file.remove(fullPath) }
      
      ggsave(fileName, 
              plot = gg.likelihood.pm.lst[[i]], 
              device = NULL, path = output.path,
              scale = 1, width = 6, height = NA, dpi = 300, limitsize = TRUE,
              units = c("in", "cm", "mm"))
      
    }
    

```


```{r printDiags2, echo=FALSE, include=TRUE, results="hide", message=F, warning=T, out.width=c('33%', '33%', '33%'), fig.show='hold'}

    for (i in 2:length(gg.lst)) {
  
      print(gg.lst[[i]])
  
      fileName <- paste("ggsave.poisson.", i, ".4.2.V2.pdf", sep="")
      fullPath <- paste(output.path, "/", fileName, sep="")
      if (file.exists(fullPath)) { file.remove(fullPath) }

      ggsave(fileName, plot = gg.lst[[i]], 
              device = NULL, path = output.path,
              scale = 1, width = 6, height = NA, dpi = 300, limitsize = TRUE,
              units = c("in", "cm", "mm"))
      
    }
```


```{r binomial, echo=FALSE, include=TRUE, results='asis', message=F, warning=T}
if (FALSE) {
# Compute likelihood function from 1’s and 0’s
# https://bookdown.org/content/3686/inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-likelihood-function-the-bernoulli-distribution
# > bernoulli_likelihood(.25, c(0,1,0,1,0,1,0,0,1,1,1,0,0,0,0))
# 1] 1.833122e-05
# > 

#=============================================================
source('/Users/rcphelps/code/thesis/ampelos/code/kruschke.R')

#=============================================================
# specify a prior
# https://bookdown.org/content/3686/inferring-a-binomial-probability-via-exact-mathematical-analysis.html#specifying-a-beta-prior.

prior <- visualizeBeta(mean = binomial.spiders.pm.control.p1.theta,
                       mode = binomial.spiders.pm.control.p1.theta * .9, 
                       shape1=7, shape2=17)

print(prior[[1]])

#=============================================================
# the bernoulli MLE estimate (theta) is simply the sample mean
# https://web.stanford.edu/class/cs109/reader/11%20Parameter%20Estimation.pdf

#=============================================================
# create a likelihood from observations
# https://bookdown.org/content/3686/inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-likelihood-function-the-bernoulli-distribution

binomial.control.p1 <- bernoulli_likelihood(theta = binomial.spiders.pm.control.p1.theta, 
                                            data = binomial.spiders.pm.control.p1.tbl)

binomial.SNH.p1 <- bernoulli_likelihood(theta = binomial.spiders.pm.SNH.p1.theta, 
                                        data = binomial.spiders.pm.SNH.p1.tbl)

#=============================================================
# build prior, likelihood, and posterior

# Determining the Effective Sample Size of a Parametric Prior
# # https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3081791/
# effective sample size (ESS) = a + b = 'kappa'

## --- READ READ READ https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3081791/ --- ##
#      "If the prior is elicited from a domain expert, then an informative prior is desirable"
# for the prior, examine the first 30 observations; 5 positives
# 5/30 = 0.167
preObsTraps <- 30
preObsSpiders <- 5
preObsMean <- preObsSpiders / preObsTraps
pdfMass <- .95
  
# define the prior
essPrior <- betaABfromMeanKappa(mean = preObsMean, kappa = preObsTraps)
hdiPrior <- hdi_of_icdf(name = qbeta, 
                        shape1 = essPrior$a, 
                        shape2 = essPrior$b, 
                        width = pdfMass)

trial.data <- binomial.spiders.pm.control.p1.tbl$Thomisidae..crab.spider.

n <- length(trial.data)
z <- sum(trial.data)

# compute the HDIs for the posterior
hdiPost <- hdi_of_icdf(name = qbeta, 
                        shape1 = z + essPrior$a,
                        shape2 = n - z + essPrior$b, 
                        width = pdfMass)

# is there overlap of the two hdi intervals?
# overlap(hdiPrior[[1]], hdiPrior[[2]], hdiPost[[1]], hdiPost[[2]])


  
distributions <- tibble(theta = seq(from = 0, to = 1, length.out = 100)) %>% 
                  mutate(prior = dbeta(theta, 
                                       shape1 = essPrior$a, 
                                       shape2 = essPrior$b)) %>%
                  mutate(like = bernoulli_likelihood(
                                       theta = theta, data = trial.data)) %>%
                  mutate(post = dbeta( theta, 
                                       shape1 = z + essPrior$a, 
                                       shape2 = n - z + essPrior$b))
                        

rtn <- priorLikePost(distributions)

print(rtn[[1]])

# Create a distribution
# posterior <- distribution_gamma(10000, 1.5)
# https://easystats.github.io/bayestestR/ (under “point estimates”)


# separate a series of observations into 10 series of increasing length
chop.lst <- chopObservations(sourceData = binomial.spiders.pm.control.p1.tbl$Thomisidae..crab.spider., chopFactor = 27)


# compare the hdi range of 2 observation sets for overlap
hdi.tbl <- compareObservations(prior.data=chop.lst[[1]], 
              trialA.data = binomial.spiders.pm.control.p1.tbl$Thomisidae..crab.spider., 
              trialB.data = binomial.spiders.pm.SNH.p1.tbl$Thomisidae..crab.spider.,
              beginPdfMass = 0.60)

if (FALSE) {
  
  hdi.tbl <- compareObservations(prior.data=chop.lst[[1]], 
              trialA.data = binomial.spiders.pm.control.p1.tbl$Thomisidae..crab.spider., 
              trialB.data = chop.lst[[5]],
              beginPdfMass = 0.60)
  
}

# produce posterior graphs and parameter data
pair.lst <- posteriorPair(data=hdi.tbl)

print(pair.lst[[1]])

}

```


```{r chi-squared, echo=FALSE, include=FALSE, results='asis', message=F, warning=T}

if (FALSE) {
  

################ ignore: INSUFFICIENT SAMPLES and count magnitude (many zeros) FOR CHI_SQ
################
################

# The Coefficient of Variation is the ratio of the standard deviation to the mean. It is always dimensionless (i.e. it is a plain number without a unit) and is scale invariant (in other words, you can make changes to the length, height or other scale factors without it affecting the result).
# The Index of Dispersion is the ratio of the variance to the mean (hence the alternate name variance to mean ratio). I usually has a dimension (unless being applied to dimensionless counts) and it is not scale invariant.
# https://www.statisticshowto.com/index-of-dispersion/

# index of dispersion
# Practical Statistics for Field Biology. Fowler, Cohen, Jarvis
# Fowler, J., Cohen, L., & Jarvis, P. (1998). Practical statistics for field biology. Chichester: Wiley.
#
#



# with df=29 and chisq statistic > 50 the significance level is
# > 0.01. (appendix 3 ; Fowler, Cohen, Jarvis)

# rcp> We conclude that if the control transect spider counts are distributed 
# homogeneously, then a count difference of this magnitude would occur randomly 
# in fewer than 1% of equivalent surveys.

stats <- chiSqStats(thomisidae.period1.SNH.tibl, thomisidae.period1.control.tibl)

stats.tbl <- tribble(~transect, ~dispersionIndex, ~degreesFreedom, ~chiSq,
            "SNH", round(stats[[1]],3), round(stats[[2]],3), round(stats[[3]],3),
            "control", round(stats[[4]],3), round(stats[[5]],3), round(stats[[6]],3)
                      )

knitr::kable(stats.tbl, caption="INSUFFICIENT SAMPLES FOR CHI_SQ\nComparison of SNH and Control trapped\nspider totals by position (Chi Squared test)",
             col.names = c("transect", 
                           "dispersion index", 
                           "degrees of freedom", 
                           "chi squared"),
             align = "lccc")

}

```





```{r bayesPowerStats, echo=FALSE, include=TRUE, results='asis', message=F, warning=T}

if (FALSE) {
  
  # https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Poisson.html
  require(graphics)

  -log(dpois(0:7, lambda = 1) * gamma(1+ 0:7)) # == 1
  Ni <- rpois(50, lambda = 4); table(factor(Ni, 0:max(Ni)))

  1 - ppois(10*(15:25), lambda = 100)  # becomes 0 (cancellation)
      ppois(10*(15:25), lambda = 100, lower.tail = FALSE)  # no cancellation

  par(mfrow = c(2, 1))
  x <- seq(-0.01, 5, 0.01)
  plot(x, ppois(x, 1), type = "s", ylab = "F(x)", main = "Poisson(1) CDF")
  plot(x, pbinom(x, 100, 0.01), type = "s", ylab = "F(x)",
     main = "Binomial(100, 0.01) CDF")


# install.packages(c("coda","mvtnorm","devtools","loo"))
#library(devtools)
#devtools::install_github("rmcelreath/rethinking")
#
#library(rethinking)
#rethinking::precis(m10.10, corr=TRUE)
#'data.frame': 8000 obs. of 15 variables:
#                           mean   sd   5.5%  94.5%      histogram
#b_Intercept                3.97 4.95  -3.92  11.93       ▁▁▃▇▇▂▁▁
#b_log_pop                 -0.01 1.01  -1.63   1.60 ▁▁▁▂▃▅▇▇▅▃▂▁▁▁
#b_contact_high             0.00 0.98  -1.57   1.58      ▁▁▂▇▇▂▁▁▁
#b_log_pop.contact_high    -0.05 0.20  -0.38   0.28      ▁▁▁▃▇▇▂▁▁
#lp__                     -66.40 1.43 -69.08 -64.78    ▁▁▁▁▁▁▂▂▅▇▂
#b_Intercept.1              2.47 3.70  -3.47   8.29        ▁▁▃▇▃▁▁
#b_log_pop.1                0.00 1.00  -1.57   1.60      ▁▁▂▇▇▂▁▁▁
#b_contact_high.1          -0.01 0.94  -1.51   1.49 ▁▁▁▂▃▇▇▇▅▃▁▁▁▁
#b_log_pop.contact_high.1   0.00 0.26  -0.41   0.41     ▁▁▁▃▇▇▃▁▁▁
#lp__.1                   -42.40 1.38 -45.01 -40.80    ▁▁▁▁▁▁▂▂▅▇▂
#b_Intercept.2              1.43 2.81  -3.09   5.89    ▁▁▁▂▅▇▇▃▁▁▁
#b_log_pop.2                0.00 0.99  -1.57   1.58      ▁▁▂▇▇▂▁▁▁
#b_contact_high.2           0.01 0.95  -1.50   1.53       ▁▁▂▇▇▂▁▁
#b_log_pop.contact_high.2   0.10 0.36  -0.48   0.66 ▁▁▁▁▂▃▇▇▇▃▂▁▁▁
#lp__.2                   -24.60 1.44 -27.29 -22.96   ▁▁▁▁▁▁▁▂▃▇▇▁

#plot(rethinking::precis(m10.10))
  
detach("package:rethinking", unload=TRUE, character.only = TRUE) 



# https://bookdown.org/content/3686/goals-power-and-sample-size.html#the-will-to-power
# paragraph 13.1

# lambda is a vector of non-negative means
lambda <- seq(from = 0.01, to = 5, by = 0.01)

#
# https://stackoverflow.com/questions/61139218/create-a-multiple-plot-distibution-of-many-variables-into-one

p_dat <- map_df(1:10, ~ tibble(
  l = paste(.),
  # x = 0:5,
  x = seq(from = 0, to = 1, by = .2),
  y = dpois(0:5, .),
  d = "pois"
))

ggplot(p_dat, aes(x, y, color = factor(l, levels = 1:10))) +
  geom_line() +
  geom_point(data = p_dat, aes(x, y, color = factor(l, levels = 1:10))) +
  labs(color = "Lambda:") +
  theme_minimal()


#https://github.com/easystats/bayestestR#documentation
install.packages("bayestestR")
library(bayestestR)

bayestestR::equivalence_test(test.lst[[3]][[1]], range=c(-0.15, 0.15), ci=0.89)
bayestestR::equivalence_test(test.lst[[3]][[2]], range=c(-0.2, 0.2), ci=0.89)
bayestestR::equivalence_test(test.lst[[3]][[3]], range=c(-0.2, 0.2), ci=0.89)

detach("package:bayestestR", unload=TRUE, character.only = TRUE) 
}



```

